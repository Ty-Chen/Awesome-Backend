计算机系统面试攻略
====

对于计算机系统，常见面试题包括以下部分
1. 线程，进程和协程

2. CPU相关

3. 内存调用和堆栈

4. Linux系统问题

---
### 进程、线程和协程

* #### 进程调度算法
  - 先来先服务 （FCFS，first come first served）

    在所有调度算法中，最简单的是非抢占式的FCFS算法。

    算法原理：进程按照它们请求CPU的顺序使用CPU.就像你买东西去排队，谁第一个排，谁就先被执行，在它执行的过程中，不会中断它。当其他人也想进入内存被执行，就要排队等着，如果在执行过程中出现一些事，他现在不想排队了，下一个排队的就补上。此时如果他又想排队了，只能站到队尾去。

    算法优点：易于理解且实现简单，只需要一个队列(FIFO)，且相当公平

    算法缺点：比较有利于长进程，而不利于短进程，有利于CPU 繁忙的进程，而不利于I/O 繁忙的进程

  - 最短作业优先（SJF, Shortest Job First）

    短作业优先（SJF, Shortest Job First）又称为“短进程优先”SPN(Shortest Process Next)；这是对FCFS算法的改进，其目标是减少平均周转时间。

    算法原理：对预计执行时间短的进程优先分派处理机。通常后来的短进程不抢先正在执行的进程。

    算法优点：相比FCFS 算法，该算法可改善平均周转时间和平均带权周转时间，缩短进程的等待时间，提高系统的吞吐量。

    算法缺点：对长进程非常不利，可能长时间得不到执行，且未能依据进程的紧迫程度来划分执行的优先级，以及难以准确估计进程的执行时间，从而影响调度性能。

  - 最高响应比优先法(HRRN，Highest Response Ratio Next)

      最高响应比优先法(HRRN，Highest Response Ratio Next)是对FCFS方式和SJF方式的一种综合平衡。FCFS方式只考虑每个作业的等待时间而未考虑执行时间的长短，而SJF方式只考虑执行时间而未考虑等待时间的长短。因此，这两种调度算法在某些极端情况下会带来某些不便。HRN调度策略同时考虑每个作业的等待时间长短和估计需要的执行时间长短，从中选出响应比最高的作业投入执行。这样，即使是长作业，随着它等待时间的增加，W / T也就随着增加，也就有机会获得调度执行。这种算法是介于FCFS和SJF之间的一种折中算法。
      算法原理：响应比R定义如下： R =(W+T)/T = 1+W/T
      其中T为该作业估计需要的执行时间，W为作业在后备状态队列中的等待时间。每当要进行作业调度时，系统计算每个作业的响应比，选择其中R最大者投入执行。

      算法优点：由于长作业也有机会投入运行，在同一时间内处理的作业数显然要少于SJF法，从而采用HRRN方式时其吞吐量将小于采用SJF 法时的吞吐量。

      算法缺点：由于每次调度前要计算响应比，系统开销也要相应增加。
      
    - 时间片轮转算法（RR，Round-Robin）
  
      该算法采用剥夺策略。时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称RR调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
  
      算法原理：让就绪进程以FCFS 的方式按时间片轮流使用CPU 的调度方式，即将系统中所有的就绪进程按照FCFS 原则，排成一个队列，每次调度时将CPU 分派给队首进程，让其执行一个时间片，时间片的长度从几个ms 到几百ms。在一个时间片结束时，发生时钟中断，调度程序据此暂停当前进程的执行，将其送到就绪队列的末尾，并通过上下文切换执行当前的队首进程，进程可以未使用完一个时间片，就出让CPU（如阻塞）。
  
      算法优点：时间片轮转调度算法的特点是简单易行、平均响应时间短。
  
      算法缺点：不利于处理紧急作业。在时间片轮转算法中，时间片的大小对系统性能的影响很大，因此时间片的大小应选择恰当

---

* #### 协程是什么？

  协程主要应用场景是高性能的**网络服务**。

  对**网络服务器**来说，

  - 大量的来自客户端的请求包和服务器的返回包，都是网络 IO；
  - 在响应请求的过程中，往往需要访问存储来保存和读取自身的状态，这也涉及本地或网络 IO。

  操作系统提供的标准网络 IO 有以下这些成本：
   系统调用机制产生的开销；

  - 数据**多次拷贝**的开销（数据总是先写到**操作系统缓存**再到用户传入的**内存**）；
  - 因为**没有数据**而阻塞，产生调度重新获得执行权，产生的时间成本；
  - **线程的空间成本和时间成本**（标准 IO 请求都是同步调用，要想 IO 请求并行只能使用更多线程）。

  逐个分析上面几点：

  - 系统调用虽然比普通函数调用多做了点事，如查询**中断向量表**，但归根到底还是一次函数调用成本而已。
  - epoll（Linux）或 IOCP（Windows）两个机制颇为类似，都是在需要 IO 时**登记一个 IO 请求**，然后统一在**某个线程查询谁的 IO** 先完成了，谁先完成了就让谁处理。从系统调用次数的角度，epoll 或 IOCP 都是**产生了更多次数的**系统调用。
  - 从内存拷贝来说**也没有减少**。
  - 所以真正最有意义的事情是：减少了线程的数量。

  进一步分析线程的成本。首先，时间成本可以拆解为：

  - 执行体（进程、线程或协程）**切换本身**的开销，它主要是**寄存器保存和恢复**的成本，可腾挪的余地非常有限；
  - 执行体的**调度**开销，它主要是如何在大量已**准备好的执行体中选出谁获得**执行权；
  - 执行体之间的**同步与互斥**成本。

  再看线程的空间成本。它可以拆解为：

  - 执行体的**执行状态**；
  - TLS（线程**局部存储**）；
  - 执行体的**堆栈**。

  显然，上述成本的比重各不相同。

  - 默认情况下 Linux 线程在数 MB 左右，其中最大的成本是堆栈。如果一个线程 1MB，那么有 1000 个线程就已经到 GB 级别了。
  - 执行体的调度开销，以及执行体之间的同步与互斥成本，也是一个不可忽略的成本。虽然单位成本看起来不大，但是次数实在太多。

  所以，降低执行体的空间成本和时间成本带来的收益比较可观。协程就是奔着这个目的来的。

---

* #### 不同语言对协程的支持程度如何？技术难点在哪里？

  一个完备的协程库可以理解为用户态的**操作系统**，而协程就是**用户态操作系统里面的 “进程”**。
   这世界上有完备的协程库么？有。有两个语言干了这事儿：Erlang 和 Go 语言。Go 语言里面的用户态 “进程” 叫 goroutine。它有这样一些重要设计：

  - 堆栈**开始很小（只有 4K），但可按需自动增长**；
  - 坚决干掉了 “线程局部存储（TLS）” 特性的支持，让执行体更加精简；
  - 提供了同步、互斥和其他常规执行体间的通讯手段，包括大家非常喜欢的 channel；
  - 提供了几乎所有重要的系统调用（尤其是 IO 请求）的包装。

  大部分你看到的协程（纤程）库只是一个半吊子。它们都只实现了协程的创建和执行权的切换，缺了非常多的内容。包括：

  - 协程的调度；
  - 协程的同步、互斥与通讯；
  - 协程的系统调用包装，尤其是网络 IO 请求的包装。

  其中最难搞的就是**堆栈**。因为，协程的**堆栈**如果太小则可能不够用；而如果太大则协程的空间成本过高，影响能够处理的网络请求的并发数。理想情况下，**堆栈大小需要能够自动适应需要**。

---

* #### 多线程如何同步
  windows --- 线程同步有四种方式：临界区、内核对象、互斥量、信号量。<br>
  Linux --- 线程同步有最常用的是：互斥锁、条件变量和信号量。

-----
* #### 进程间通讯的方式有哪些，各有什么优缺点
  linux下进程间通信的几种主要手段：

  1. 管道（Pipe）及有名管道（named pipe）：管道可用于具有亲缘关系进程间的通信，有名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；

  2. 信号（Signal）：信号是比较复杂的通信方式，用于通知接受进程有某种事件生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux除了支持Unix早期 信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上， 该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，sigaction函数重新实现了signal函数）；
  3. 报文（Message）队列（消息队列）：消息队列是消息的链接表，包括Posix消息队列system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点；
  4. 共享内存：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针其他通信机制运行效率较低设计的。往往与其它通信机制，如信号量结合使用， 来达到进程间的同步及互斥。
  5. 信号量（semaphore）：主要作为进程间以及同一进程不同线程之间的同步手段。
  6. 套接字（Socket）：更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由Unix系统的BSD分支开发出来的，但现在一般可以移植到其它类Unix 系统上：Linux和System V的变种都支持套接字。

-----

* #### fork()一子进程后父进程全局变量能不能使用？
  fork后子进程将会拥有父进程的几乎一切资源，父子进程的都各自有自己的全局变量。不能通用，不同于线程。对于线程，各个线程共享全局变量。Fork返回0为子进程，父进程返回编号。

-----

* #### 内核级线程与用户级线程
  答：内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。

  用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。
  用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。

  在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。
  用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。

-----

* #### 线程同步机制？
  1. 原子操作函数、无锁化编程：不使用系统提供的锁，而是直接利用cpu提供的指令，实现互斥操作。在原子操作函数的执行不会被打断或被干涉。线程执行原子函数的过程不会被中断。

  2. 互斥锁：互斥锁用于确保同一个时间只有一个线程能访问被互斥锁保护的资源。加锁互斥量的线程和解锁互斥量的线程必须是同一个线程。

  3. 读写锁：读写锁有3种状态：读模式下加锁状态，写模式下加锁状态，不加锁状态。一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。

  4. 自旋锁：自旋锁和互斥量类似，但是它不是通过休眠使线程阻塞，而是在获取锁之前一直处理忙等待（自旋）的阻塞状态。自旋锁可用于以下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多成本。

  5. 条件变量：条件变量与互斥量一起使用时，允许线程以无竞争的方式等待特定的条件发生。

  6. 屏障：屏障是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，知道所有的合作线程都达到某一点，然后从该点继续执行。它允许任意数量的线程等待，直到所有的线程完成处理工作。

    一个双核的机器上有两个线程(线程A和线程B)，它们分别运行在Core0和Core1上。假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞 (blocking)，Core0 会在此时进行上下文切换(Context Switch)将线程A置于等待队列中，此时Core0就可以运行其他的任务(例如另一个线程C)而不必进行忙等待。而Spin lock则不然，它属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，那么线程A就会一直在Core0上进行忙等待并不停的进行锁请求，直到得到这个锁为止。

-----

* #### 什么是死锁？如何避免死锁？
  死锁就是两个或多个进程被无限期地阻塞、相互等待的一种状态；

  产生死锁的必要条件：

  　　（1）互斥，一个资源每次只能被一个进程使用

  　　（2）不可抢占，进程已获得的资源，在未使用完之前，不能强行剥夺

  　　（3）占有并等待，一个进程因请求资源而阻塞时，对已获得的资源保持不放

  　　（4）环形等待，若干进程之间形成一种首尾相接的循环等待资源关系。

    预防死锁

    　　破坏产生死锁的四个必要条件中的一个或者几个，来预防发生死锁。由于所施加的限制条件往往太严格，可能会导致系统资源利用率和系统吞吐量降低。

    避免死锁

    　　在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁。

    检测死锁

    　　允许系统在运行过程中发生死锁,但可通过系统所设置的检测机构，及时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源，然后采取适当措施，从系统中将已发生的死锁清除掉。

    解除死锁

    　　这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须将进程从死锁状态中解脱出来。常用的实施方法是撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。死锁的检测和解除措施，有可能使系统获得较好的资源利用率和吞吐量，但在实现上难度也最大。

-----



### CPU相关

* #### 多级反馈队列(Multilevel Feedback Queue)
  多级反馈队列调度算法是一种CPU处理机调度算法，UNIX操作系统采取的便是这种调度算法。
多级反馈队列调度算法描述：

  　　1. 进程在进入待调度的队列等待时，首先进入优先级最高的Q1等待。

  　　2. 首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程。例如：Q1,Q2,Q3三个队列，只有在Q1中没有进程等待时才去调度Q2，同理，只有Q1,Q2都为空时才会去调度Q3。

  　　3. 对于同一个队列中的各个进程，按照时间片轮转法调度。比如Q1队列的时间片为N，那么Q1中的作业在经历了N个时间片后若还没有完成，则进入Q2队列等待，若Q2的时间片用完后作业还不能完成，一直进入下一级队列，直至完成。

  　　4. 在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU马上分配给新到达的作业（抢占式）。

  　　在多级反馈队列调度算法中，如果规定第一个队列的时间片略大于多数人机交互所需之处理时间时，便能够较好的满足各种类型用户的需要。

---


### 内存和堆栈


* #### 内存分配

1. 栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其
操作方式类似于数据结构中的栈。

2. 堆区（heap） — 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回
收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表，呵呵。
3. 全局区（静态区）（static）—，全局变量和静态变量的存储是放在一块的，初始化的
全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另
一块区域。 - 程序结束后由系统释放。
4. 文字常量区 —常量字符串就是放在这里的。 程序结束后由系统释放
5. 程序代码区—存放函数体的二进制代码。

-----

* #### 堆和栈的区别？
  - 管理方式：对于栈来讲，是由编译器自动管理，无需我们手工控制；对于堆来说，释放工作由程序员控制，容易产生memory leak。

  - 空间大小：一般来讲在 32位系统下，堆内存可以达到4G的空间。但是对于栈来讲，一般都是有一定的空间大小的。
  - 碎片问题：对于堆来讲，频繁的 new/delete 势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题。
  - 生长方向：对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。
  - 分配方式：堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由malloc函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。
  - 分配效率：栈的效率比较高。堆的效率比栈要低得多。

-----
* #### 函数调用栈里面存储的是什么
   [see this blog](http://blog.csdn.net/yang_yulei/article/details/45795591)

-----

* #### 共享内存段被映射进进程空间之后，存在于进程空间的什么位置？共享内存段最大限制是多少？
  mmap函数要求内核创建一个新的虚拟存储器区域，最好是从地址start开始的一个区域，并将文件描述符fd指定对象的一个连续的片（chunk）映射到这个新的区域。
  SHMMNI为128，表示系统中最多可以有128个共享内存对象。

-----


* #### Linux的内存管理机制？
  Linux采用虚拟内存机制和分页机制来管理内存。

  直接从物理内存读写数据要比从硬盘读写数据要快的多，因此，我们希望所有数据的读取和写入都在内存完成，而内存是有限的，所以引入了虚拟内存机制。

  物理内存就是系统硬件提供的内存大小，是真正的内存，相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。

  linux会在物理内存不足时会将暂时不用的内存块信息写到交换空间，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。

  Linux的内存管理采取的是分页存取机制，将进程空间放在多个页中。进程运行时不是所有的页都在内存中，而只是一部分而已。每个进程有个页表来指明某个页是否在物理内存中，如果在则写明该页在物理内存中的页框号；否则该页在虚拟内存中，当进程需要用到出狱虚拟内存中的页面时，会产生缺页异常，操作系统会根据一定的页面置换算法将该页面调入物理内存。

  进程包含一个虚拟地址（页号+偏移量），寄存器保存了页表的基地址，页号指出了页表中的页表项，得到该页在物理内存中的页框号，页框号+偏移量就是物理地址。

  页面置换算法：

  1. 最佳OPT ：选择置换下次访问距当前时间最长的那些页，可以看出这能导致最少的缺页中断，但是由于它要求操作系统必须知道将来的事情，显然是不可实现的。只能作为性能衡量标准。
2. 最近最少使用LRU ：置换内存中上次使用距当前最远的页。根据局部性原理，这也是最不可能访问的页。为每一页添加最后一次访问的时间戳，或者维护一个页的访问栈。性能优异，但两种方法都开销大。
  3. 先进先出FIFO ：把分配给进程的页框视为一个循环缓冲区，按循环方式移动页。即选择驻留在内存时间最长的页。但这个推断常常是错的。
  4. 时钟Clock ：开销较小但性能接近LRU。为每个页框关联一个附加位。当被访问到时置1。置换的候选页框集合视为一个循环缓冲区，指针扫描缓冲区，选择第一个附加为位0的页框进行置换。当指针划过一个附加位为1的，则置0。可以增加关联的附加位让时钟策略更有效。除了访问的附加位，还可以添加修改的附加位。
  5. 最近次数最少LFU，要求在页置换时置换引用计数最小的

---

* #### 内存调度算法bubby system和slab

  [see this](https://zhuanlan.zhihu.com/p/36140017)

-----

### Linux系统问题

* #### 守护进程？
  Linux Daemon（守护进程）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。它不需要用户输入就能运行而且提供某种服务，不是对整个系统就是对某个用户程序提供服务。Linux系统的大多数服务器就是通过守护进程实现的。常见的守护进程包括系统日志进程syslogd、 web服务器httpd、邮件服务器sendmail和数据库服务器mysqld等。

  守护进程一般在系统启动时开始运行，除非强行终止，否则直到系统关机都保持运行。守护进程经常以超级用户（root）权限运行，因为它们要使用特殊的端口（1-1024）或访问某些特殊的资源。

  一个守护进程的父进程是init进程，因为它真正的父进程在fork出子进程后就先于子进程exit退出了，所以它是一个由init继承的孤儿进程。守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理。

  守护进程的名称通常以d结尾，比如sshd、xinetd、crond等

---

* #### Linux的任务调度机制和调度时机
  ​       linux进程的调度时机大致分为两种情况： 一种是进程自愿调度；另一种是发生强制性调度。

  ​      首先，自愿的调度随时都可以进行。在内核空间中，进程可以通过schedule()启动一次调度；在用户空间中，可以通过系统调用pause()达到同样的目的。如果要为自愿的暂停行为加上时间限制，在内核中使用schedule_time(),而在用户空间则使用nanosleep()系统调用。 linux中，强制性的调度发生在每次从系统调用返回的前夕，以及每次中断或异常处理返回用户空间的前夕。应注意的是，从内核态返回到用户态是进程调度发生的必要条件，而不是充分条件，还要取决于当进程task_struct结构中的need_resched是否为1。

  从进程调度的时机可以看出，内核的调度方式为“有条件的剥夺方式”。当进程在用户空间运行，不管自愿不自愿，一旦有必要比如时间片用完，内核就可以暂时剥夺其运行而调度其他进程运行。而进程一旦进入内核空间，即进入核心态时，尽管知道应该要调度了，但实际上却不会发生，一直要到该进程返回到用户空间前夕才能剥夺其运行。

  **Linux任务调度策略**

  Linux支持SCHED_FIFO、SCHED_RR和SCHED_OTHER的调度策略。
  
  linux用函数goodness（）统一计算进程（包括普通进程和实时进程）的优先级权值，该权值衡量一个处于可运行状态的进程值得运行的程度，权值越大，进程优先级越高。 每个进程的task_struct结构中，与goodness（）计算权值相关的域有以下四项：policy、nice(2.2版内核该项为priority)、counter、rt_priority。其中，policy是进程的调度策略，其可用来区分实时进程和普通进程，实时进程优先于普通进程运行。nice从最初的UNIX沿用而来，表示进程的静态负向优先级，其取值范围为19~-20，以-20优先级最高。counter表示进程剩余的时间片计数值，由于counter在计算goodness（）时起重要作用，因此，counter也可以看作是进程的动态优先级。rt_priority是实时进程特有的，表示实时优先级。

-----

* #### 32位系统一个进程最多多少堆内存？
  32位linux不打开PAE，则最多只能识别出4GB内存，若打开PAE，则最多可以识别出64GB内存。但是 32位系统下的进程一次最多只能寻址4GB的空间。

-----

* #### linux的五种IO方式（阻塞与非阻塞、同步与异步的理解）
  同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回,但是当前线程还是激活的。
  异步，就是调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。

  阻塞调用是指调用结果返回之前，当前线程会被挂起（线程进入非可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行）。函数只有在得到结果之后才会返回。
  非阻塞调用，不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。

  阻塞和非阻塞是指当进程访问的数据如果尚未就绪,进程是否需要等待,也就是未就绪时是直接返回还是等待就绪;而同步和异步是指访问数据的机制,同步一般指主动请求并等待I/O操作完毕的方式,当数据就绪后在读写的时候必须阻塞,异步则指主动请求数据后便可以继续处理其它任务,随后等待I/O,操作完毕的通知,这可以使进程在数据读写时也不阻塞。

  也就是说阻塞和非阻塞是指数据未到达时要不要等待，而同步异步是指收到通知的方式。

  Linux下的五种I/O模型

  - 阻塞I/O:进程会一直阻塞，直到数据拷贝完成

  - 非阻塞I/O:非阻塞IO通过进程反复调用IO函数（多次系统调用，并马上返回）；在数据拷贝的过程中，进程是阻塞的；
  - I/O复用(select 和poll)：主要是select和epoll；对一个IO端口，两次调用，两次返回，比阻塞IO并没有什么优越性；关键是能实现同时对多个IO端口进行监听。
  - 信号驱动I/O ：允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。
  - 异步I/O：当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作。



-----

* #### linux中断响应机制
  ​        当一个中断发生时，并不是所有的操作都具有相同的急迫性。事实上，把所有的操作都放进中断处理程序本身并不合适。需要时间长的、非重要的操作应该推后，因为当一个中断处理程序正在运行时，相应的IRQ中断线上再发出的信号就会被忽略。另外中断处理程序不能执行任何阻塞过程，如I/O设备操作。因此，Linux把一个中断要执行的操作分为下面的三类：

  1. 紧急的（Critical）

      这样的操作诸如：中断到来时中断控制器做出应答，对中断控制器或设备控制器重新编程，或者对设备和处理器同时访问的数据结构进行修改。这些操作都是紧急的，应该被很快地执行，也就是说，紧急操作应该在一个中断处理程序内立即执行，而且是在禁用中断的状态下。

  2. 非紧急的（Noncritical）

      这样的操作如修改那些只有处理器才会访问的数据结构（例如，按下一个键后，读扫描码）。这些操作也要很快地完成，因此，它们由中断处理程序立即执行，但在启用中断的状态下。

  3.  非紧急可延迟的（Noncritical deferrable）

      这样的操作如，把一个缓冲区的内容拷贝到一些进程的地址空间（例如，把键盘行缓冲区的内容发送到终端处理程序的进程）。这些操作可能被延迟较长的时间间隔而不影响内核操作，有兴趣的进程会等待需要的数据。
      所有的中断处理程序都执行四个基本的操作：

      （1）在内核栈中保存IRQ的值和寄存器的内容。

      （2）给与IRQ中断线相连的中断控制器发送一个应答，这将允许在这条中断线上进一步发出中断请求。

      （3）执行共享这个IRQ的所有设备的中断服务例程（ISR）。

      （4）跳到ret_to_usr( )的地址后终止。

-----

* #### exit()与_exit()的区别？
  \_exit终止调用进程，但不关闭文件，不清除输出缓存，也不调用出口函数。exit函数将终止调用进程。在退出程序之前，所有文件关闭，缓冲输出内容将刷新定义，并调用所有已刷新的“出口函数”（由atexit定义）。

  ‘exit()’与‘\_exit()’有不少区别在使用‘fork()’，特别是‘vfork()’时变得很突出。

  ‘exit()’与‘\_exit()’的基本区别在于前一个调用实施与调用库里用户状态结构(user-mode constructs)有关的清除工作(clean-up)，而且调用用户自定义的清除程序

-----

* #### 使用连接池如何确保拿到的连接都是可用的

  一般有两种做法：

  - 启动**一个线程来定期检测连接池中的连接**是否可用，比如使用连接发送“select 1”的命令给数据库看是否会抛出异常，如果抛出异常则关闭它，并将其从连接池中移除。比如常用的**C3P0**连接池就支持这种方式。
  - 每次获取到连接后，总是先校验连接是否可用，比如**DBCP**连接池的 **testOnBorrow**配置项，就是控制是否开启这个验证。显然，这种方式引入了多余的开销，线上系统中不推荐开启。

  