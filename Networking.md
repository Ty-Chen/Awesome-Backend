网络通信面试攻略
====

网络通信方向主要考察

1. 七层架构的基本知识
2. TCP、UDP
3. HTTP
4. RPC

---

网络架构相关
-----

* #### 在子网210.27.48.21/30种有多少个可用地址？分别是什么？
  简: 30表示的是网络号(network number)是30位，剩下2位中11是广播(broadcast)地址，00是multicast地址，只有01和10可以作为host address。

  详: 210.27.48.21/30代表的子网的网络号是30位，即网络号是210.27.48.21 & 255.255.255.251=210.27.48.20，此子网的地址空间是2位，即可以有4个地址：210.27.48.20, 210.27.48.21, 210.27.48.22, 210.27.48.23。第一个地址的主机号(host number/id)是0，而主机号0代表的是multicast地址。最后一个地址的最后两位是11，主机号每一位都为1代表的是广播(broadcast)地址。所以只有中间两个地址可以给host使用。其实那个问题本身不准确，广播或multicast地止也是可以使用的地址，所以回答4也应该正确，当然问的人也可能是想要你回答2。我个人觉得最好的回答是一个广播地址，一个multicast地址，2个unicast地址。

-----

* #### 路由表示做什么用的？在linux环境中怎么来配置一条默认路由？
  路由表是用来决定如何将包从一个子网传送到另一个子网的，换局话说就是用来决定从一个网卡接收到的包应该送的哪一张网卡上的。在Linux上可以用“route add default gw <默认路由器IP>”来配置一条默认路由。

  详: 路由表是用来决定如何将包从一个子网传送到另一个子网的，换局话说就是用来决定从一个网卡接收到的包应该送的哪一张网卡上的。路由表的每一行至少有目标网络号、netmask、到这个子网应该使用的网卡。当路由器从一个网卡接收到一个包时，它扫描路由表的每一行，用里面的netmask和包里的目标IP地址做并逻辑运算(&)找出目标网络号，如果此网络号和这一行里的网络号相同就将这条路由保留下来做为备用路由，如果已经有备用路由了就在这两条路由里将网络号最长的留下来，另一条丢掉，如此接着扫描下一行直到结束。如果扫描结束任没有找到任何路由，就用默认路由。确定路由后，直接将包送到对应的网卡上去。在具体的实现中，路由表可能包含更多的信息为选路由算法的细节所用。题外话：路由算法其实效率很差，而且不scalable，解决办法是使用IP交换机，比如MPLS。
  在Linux上可以用“route add default gw <默认路由器IP>”来配置一条默认路由。

-----

* #### 在网络中有两台主机A和B，并通过路由器和其他交换设备连接起来，已经确认物理连接正确无误，怎么来测试这两台机器是否连通？如果不通，怎么来判断故障点？怎么排除故障？
  答：测试这两台机器是否连通：从一台机器ping另一台机器，如果ping不通，用traceroute可以确定是哪个路由器不能连通，然后再找问题是在交换设备/hup/cable等。

-----

* #### 网络编程中设计并发服务器，使用多进程与多线程 ，请问有什么区别？
  答案一:

  1. 进程：子进程是父进程的复制品。子进程获得父进程数据空间、堆和栈的复制品。

  2. 线程：相对与进程而言，线程是一个更加接近与执行体的概念，它可以与同进程的其他线程共享数据，但拥有自己的栈空间，拥有独立的执行序列。

  两者都可以提高程序的并发度，提高程序运行效率和响应时间。

  线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源管理和保护；而进程正相反。同时，线程适合于在SMP机器上运行，而进程则可以跨机器迁移。

  答案二:

  根本区别就一点：用多进程每个进程有自己的地址空间(address space)，线程则共享地址空间。所有其它区别都是由此而来的：

  1. 速度：线程产生的速度快，线程间的通讯快、切换快等，因为他们在同一个地址空间内。
  2. 资源利用率：线程的资源利用率比较好也是因为他们在同一个地址空间内。
  3. 同步问题：线程使用公共变量/内存时需要使用同步机制还是因为他们在同一个地址空间内。

-----

* #### 路由表的网段怎么存储、查找   
  存储：
  根据RIP协议报文（包含目的网络，距离以及下一跳），若目的网络在原路由表中不存在，则直接加入路由表中；若存在，且距离比原路由表比较小，则更新距离，否则忽略。

  查找：
  路由表中有目的地址网络，子网掩码，下一跳这些数据；
  先从数据包中获取目的地址，让该地址与路由表中的子网掩码逐个进行与操作，若结果和子网掩码对应的目的地址相匹配，则从下一跳指向的端口进行转发，否则查找下一个路由表项；

-----

* #### dns怎么解析的？
  1. 主机通过ISP接入了互联网，那么ISP就会分配一个DNS服务器；

  2. 主机向ISP DNS发起查询www.baidu.com请求；

  3. ISP DNS收拿到请求后，先检查一下自己的缓存中有没有这个地址，有的话就直接返回,如果缓存中没有的话，ISP DNS会从配置文件里面读取13个根域名服务器的地址。并向其中一台发起请求。

  4. 根服务器拿到这个请求后，知道他是com.这个顶级域名下的，所以就会返回com域中的NS记录;

  5. ISP DNS向其中一台再次发起请求，com域的服务器发现你这请求是baidu.com这个域的，一查发现了这个域的NS，那我就返回给你，你再去查;

  6. ISP DNS不厌其烦的再次向baidu.com这个域的权威服务器发起请求，baidu.com收到之后，查了下有www的这台主机，就把这个IP返回给你了;

  7. 然后ISPDNS拿到了之后，将其返回给了客户端，并且把这个保存在高速缓存中。

-----

* #### ipv4与ipv6
  1. IPv6具有更大的地址空间。IPv4中规定IP地址长度为32，最大地址个数为232；而IPv6中IP地址的长度为128，即最大地址个数为2128。与32位地址空间相比，其地址空间增加了2128-232个。

  2. IPv6使用更小的路由表。IPv6的地址分配一开始就遵循聚类（Aggregation）的原则，这使得路由器能在路由表中用一条记录（Entry）表示一片子网，大大减小了路由器中路由表的长度，提高了路由器转发数据包的速度。

  3. IPv6增加了增强的组播（Multicast）支持以及对流的控制（Flow Control），这使得网络上的多媒体应用有了长足发展的机会，为服务质量（QoS，Quality of Service）控制提供了良好的网络平台。

  4. IPv6加入了对自动配置（Auto Configuration）的支持。这是对DHCP协议的改进和扩展，使得网络（尤其是局域网）的管理更加方便和快捷。

  5. IPv6具有更高的安全性。在使用IPv6网络中用户可以对网络层的数据进行加密并对IP报文进行校验，在IPV6中的加密与鉴别选项提供了分组的保密性与完整性。极大的增强了网络的安全性。

  6. 允许扩充。如果新的技术或应用需要时，IPV6允许协议进行扩充。

  7. 更好的头部格式。IPV6使用新的头部格式，其选项与基本头部分开，如果需要，可将选项插入到基本头部与上层数据之间。这就简化和加速了路由选择过程，因为大多数的选项不需要由路由选择。

  8. 新的选项。IPV6有一些新的选项来实现附加的功能。

---

TCP/IP知识
-----


* #### tcp和udp的区别
  TCP:传输控制协议,提供的是面向连接、可靠的字节流服务。当客户和服务器彼此交换数据前，必须先在双方之间建立一个TCP连接，之后才能传输数据。TCP提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。  

  UDP:用户数据报协议，是一个简单的面向数据报的运输层协议。UDP不提供可靠性，它只是把应用程序传给IP层的数据报发送出去，但是并不能保证它们能到达目的地。由于UDP在传输数据报前不用在客户和服务器之间建立一个连接，且没有超时重发等机制，故而传输速度很快

-----

* #### 流量控制和拥塞控制
  拥塞控制 --- 网络拥塞现象是指到达通信子网中某一部分的分组数量过多,使得该部分网络来不及处理,以致引起这部分乃至整个网络性能下降的现象,严重时甚至会导致网络通信业务陷入停顿,即出现死锁现象。拥塞控制是处理网络拥塞现象的一种机制。  
  流量控制 --- 数据的传送与接收过程当中很可能出现收方来不及接收的情况,这时就需要对发方进行控制,以免数据丢失。流量控制用于防止在端口阻塞的情况下丢帧，这种方法是当发送或接收缓冲区开始溢出时通过将阻塞信号发送回源地址实现的。流量控制可以有效的防止由于网络中瞬间的大量数据对网络带来的冲击，保证用户网络高效而稳定的运行。

-----

* #### tcp连接建立的时候3次握手，断开连接的4次握手的具体过程
  TCP提供的可靠数据传输服务，是依靠接收端TCP软件按序号对收到的数据分组进行逐一确认实现的。

  三次握手协议指的是在发送数据的准备阶段，服务器端和客户端之间需要进行三次交互：

  第一次握手：客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；

  第二次握手：服务器收到syn包，必须确认客户的syn（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；

  第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。

  连接建立后，客户端和服务器就可以开始进行数据传输了。

  为什么客户端需要再发送一次确认？

  client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用三次握手，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用三次握手的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。

  四次挥手：

  （1）客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送。

  （2）服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。和SYN一样，一个FIN将占用一个序号。

  （3）服务器B关闭与客户端A的连接，发送一个FIN给客户端A。

  （4）客户端A发回ACK报文确认，并将确认序号设置为收到序号加1。

  为什么TCP连接是三次，挥手确是四次？

  在TCP连接中，服务器端的SYN和ACK向客户端发送是一次性发送的，而在断开连接的过程中，B端向A端发送的ACK和FIN是是分两次发送的。因为在B端接收到A端的FIN后，B端可能还有数据要传输，所以先发送ACK，等B端处理完自己的事情后就可以发送FIN断开连接了。

  为什么在第四次挥手后会有2个MSL的延时？

  MSL是Maximum Segment Lifetime，最大报文段生存时间，2个MSL是报文段发送和接收的最长时间。
  假定网络不可靠，那么第四次发送的ACK可能丢失，即B端无法收到这个ACK，如果B端收不到这个确认ACK，B端会定时向A端重复发送FIN，直到B端收到A的确认ACK。所以这个2MSL就是用来处理这个可能丢失的ACK的。而且能确保下一个新的连接中没有这个旧连接的报文。

-----


* #### epoll与select的区别
  1. select在一个进程中打开的最大fd是有限制的，由FD_SETSIZE设置，默认值是2048。不过 epoll则没有这个限制，它所支持的fd上限是最大可以打开文件的数目，这个数字一般远大于2048，一般来说内存越大，fd上限越大，1G内存都能达到大约10w左右。

  2. select的轮询机制是系统会去查找每个fd是否数据已准备好，当fd很多的时候，效率当然就直线下降了，epoll采用基于事件的通知方式，一旦某个fd数据就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，而不需要不断的去轮询查找就绪的描述符，这就是epoll高效最本质的原因。
  3. 无论是select还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的，而select则做了不必要的拷贝

-----


* #### epoll中et和lt的区别与实现原理
  LT：水平触发，效率会低于ET触发，尤其在大并发，大流量的情况下。但是LT对代码编写要求比较低，不容易出现问题。LT模式服务编写上的表现是：只要有数据没有被获取，内核就不断通知你，因此不用担心事件丢失的情况。
  ET：边缘触发，效率非常高，在并发，大流量的情况下，会比LT少很多epoll的系统调用，因此效率高。但是对编程要求高，需要细致的处理每个请求，否则容易发生丢失事件的情况。

-----

* #### connect方法会阻塞，请问有什么方法可以避免其长时间阻塞？
  最通常的方法最有效的是加定时器；也可以采用非阻塞模式。
  或者考虑采用异步传输机制，同步传输与异步传输的主要区别在于同步传输中，如果调用recvfrom后会一致阻塞运行，从而导致调用线程暂停运行；异步传输机制则不然，会立即返回。

-----

* #### 网络中，如果客户端突然掉线或者重启，服务器端怎么样才能立刻知道？
  若客户端掉线或者重新启动，服务器端会收到复位信号，每一种tcp/ip得实现不一样，控制机制也不一样。
-----

* #### TTL是什么？有什么用处，通常那些工具会用到它？（ping? traceroute? ifconfig? netstat?）
  TTL是Time To Live，一般是hup count，每经过一个路由就会被减去一，如果它变成0，包会被丢掉。它的主要目的是防止包在有回路的网络上死转，浪费网络资源。ping和traceroute用到它。

  详: TTL是Time To Live，目前是hup count，当包每经过一个路由器它就会被减去一，如果它变成0，路由器就会把包丢掉。IP网络往往带有环(loop)，比如子网A和子网B有两个路由器相连，它就是一个loop。TTL的主要目的是防止包在有回路的网络上死转，因为包的TTL最终后变成0而使得此包从网上消失(此时往往路由器会送一个ICMP包回来，traceroute就是根据这个做的)。ping会送包出去，所以里面有它，但是ping不一定非要不可它。traceroute则是完全因为有它才能成的。ifconfig是用来配置网卡的，netstat -rn 是用来列路由表的，所以都用不着它

-----

* #### 网络编程的一般步骤
  对于TCP连接：

  1. 服务器端

      - 创建套接字create；

      - 绑定端口号bind；

      - 监听连接listen；

      - 接受连接请求accept，并返回新的套接字；

      - 用新返回的套接字recv/send；

      - 关闭套接字。

    2. 客户端
        - 创建套接字create    

        - 发起建立连接请求connect;   

        - 发送/接收数据send/recv；

        - 关闭套接字。

  TCP总结：

  Server端： socket -- bind -- listen -- accept -- recv/send -- close

  Client端：socket -- conncet -- send/recv -- close.

  对于UDP连接：

  1. 服务器端:

      - 创建套接字create；

      - 绑定端口号bind；

      - 接收/发送消息recvfrom/sendto；

      - 关闭套接字。

  2. 客户端:

      - 创建套接字create；

      - 发送/接收消息sendto/recvfrom；

      - 关闭套接字.

  UDP总结:

  Server端：socket -- bind -- recvfrom/sendto -- close

  Client端：socket -- sendto/recvfrom -- close.

-----

* #### TCP的重发机制是怎么实现的？
  1. 滑动窗口机制，确立收发的边界，能让发送方知道已经发送了多少（已确认）、尚未确认的字节数、尚待发送的字节数；让接收方知道（已经确认收到的字节数）。

  2. 选择重传，用于对传输出错的序列进行重传。

-----

* #### TCP为什么不是两次连接？而是三次握手？

  **DDOS原理** 如果A与B两个进程通信，如果仅是两次连接。可能出现的一种情况就是：A发送完请报文以后，由于网络情况不好，出现了网络拥塞，即B延时很长时间后收到报文，即此时A将此报文认定为失效的报文。B收到报文后，会向A发起连接。此时两次握手完毕，B会认为已经建立了连接可以通信，B会一直等到A发送的连接请求，而A对失效的报文回复自然不会处理。依次会陷入B忙等的僵局，造成资源的浪费。
-----

* #### socket编程，如果client断电了，服务器如何快速知道？

  使用定时器（适合有数据流动的情况）；

  使用socket选项SO_KEEPALIVE（适合没有数据流动的情况）
-----

* #### tcp三次握手的过程，accept发生在三次握手哪个阶段？
  client 的 connect  引起3次握手
server 在socket， bind， listen后，阻塞在accept，三次握手完成后，accept返回一个fd，因此accept发生在三次握手之后。

-----

* #### Tcp流， udp的数据报，之间有什么区别，为什么TCP要叫做数据流？

  - TCP本身是面向连接的协议，S和C之间要使用TCP，必须先建立连接，数据就在该连接上流动，可以是双向的，没有边界。所以叫数据流 ，占系统资源多

  - UDP不是面向连接的，不存在建立连接，释放连接，每个数据包都是独立的包，有边界，一般不会合并。

  - TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证

-----

* #### socket在什么情况下可读?
  1. 接收缓冲区有数据，一定可读

  2. 对方正常关闭socket，也是可读
  3. 对于侦听socket，有新连接到达也可读
  4. socket有错误发生，且pending

-----


* #### 流量控制与拥塞控制的区别，节点计算机怎样感知网络拥塞了？
  拥塞控制是把整体看成一个处理对象的，流量控制是对单个的节点。

  节点计算机感知拥塞可以通过带宽、时延、吞吐量等方式判断

  - 通过观察网络的吞吐量与网络负载间的关系

    如果随着网络负载的增加，网络的吞吐量明显小于正常的吞吐量，那么网络就进入例如轻度拥塞的状况。

    如果网络得吞吐量随着网络负载的增大反而下降，那么网络就可能进入拥塞状态。

    如果网络的负载继续增大，而网络的吞吐量下降到零，网络就可能进入了死锁状态

  - BBR认为当吞吐量随着负载的增大下降时，说明已经存满了缓存，这是不应该的。因此BBR的检测采取了另一种方式：因为最优带宽和延迟无法同时测量（btlBw的测量会造成存在网络缓存增加RTT，而RTprop的测量要求网络缓存为空），所以分别估计带宽（btlBw）和延迟（RTprop），最后计算出cwnd。同时增加变量pacing rate（btlBw * 增益系数），用于控制发送端的发送速率，以解决发送端突发造成的网络排队问题。

-----

* #### TCP通讯中，select到读事件，但是读到的数据量是0，为什么，如何解决?
  答：select 返回0代表超时。select出错返回-1。
select到读事件，但是读到的数据量为0，说明对方已经关闭了socket的读端。本端关闭读即可。
当select出错时，会将接口置为可读又可写。这时就要通过判断select的返回值为-1来区分。

-----

* #### 用UDP协议通讯时怎样得知目标机是否获得了数据包？
  答：在UDP之上自定义一个通讯协议：每个数据包中包含一个唯一标识，可以用编号也可以用时间；接收端收到数据包后回发一个数据包，包含收到的这个唯一标识；发送端在预定时间内没有收到回执则自动重发，重发一定次数后仍未收到回执则认为发送失败。

-----

* #### 什么是滑动窗口？
  滑动窗口协议是用来改善吞吐量的一种技术，即容许发送方在接收任何应答之前传送附加的包。接收方告诉发送方在某一时刻能送多少包(称窗口尺寸)。

      TCP中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为0时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个1字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

      滑动窗口机制为端到端设备间的数据传输提供了可靠的流量控制机制。然而，它只能在源端设备和目的端设备起作用，当网络中间设备(例如路由器等)发生拥塞时，滑动窗口机制将不起作用。

-----

* #### TCP的connect函数与UDP的connect函数区别？
  在网络编程中，connect函数通常用于客户端建立tcp连接。tcp连接的建立实际上就是三次“握手”的过程。

    udp协议提供的是面向非连接的服务，通信双方不需要建立连接。一方只需要建立好套接字，并显式或由系统绑定地址和端口号后就可以发送/接收数据包。和tcp不同的是，使用udp协议的数据报套接字(SOCK_DGRAM)并不限定唯一的通信方。既可以发送（sendto）数据给任意的接受方，也可以从任意的发送方接收（recvfrom）数据。

     如果希望为一个数据报套接字指定唯一的通信方时，可以使用connect来实现这一功能。需要注意的是，在数据报套接字上使用connect并不是建立连接，不存在“握手”的过程。仅仅是为这个套接字指定一个通信方，一旦指定了对方的地址，就可以通过send/recv来发送/接收数据了。而且可以在这个数据报套接字上多次调用connect函数来指定不同的通信方。
  在udp中使用connect的方法和tcp中类似，只需在创建套接字时，把套接字的类型由SOCK_STREAM换成SOCK_DGRAM即可。

-----

* #### socket什么情况下可读、可写？
  套接字准备好读的条件:

  1. 该套接字接受缓冲区中的数据字节数大于等于套接字接受缓冲区低水位标记的当前大小。对这样的套接字执行读操作不会阻塞并将返回一个大于0的值(也就是返回准备好读入的数据)。我们可以使用SO_RCVLOWAT套接字选项设置该套接字的低水位标记。对于tcp和udp套接字而言，其默认值为1。

  2. 该套接字的读半部关闭（也就是接受了FIN的tcp连接）。对这样的套接字的读操作将不阻塞并返回0.（也就是返回EOF）

  3. 该套接字是一个监听套接字且已完成的连接数不为0。对这样的套接字的accept通常不阻塞。

  4. 其上有一个套接字错误待处理。对这样的套接字的读操作将不阻塞并返回-1（也就是返回一个错误），同时把errno设置成确切的错误条件。这样待处理错误(pending error)也可以通过指定SO_ERROR套接字选项调用getsockopt获取并清除。

  套接字准备好写的条件:

  1. 该套接字发送缓冲区中的可用空间字节数大于等于套接字发送缓冲区低水位标记的当前大小，并且或者该套接字已连接，或者该套接字不需要连接（如udp套接字）。这意味着如果我们把这样的套接字设置成非阻塞，写操作将不阻塞并返回一个正值（例如由传输层接受的字节数）。我们可以使用SO_SNDLOWAT套接字选项来设置该套接字的低水位标记。对于tcp和udp而言，其默认值通常为2048。

  2. 该连接的写半部关闭。对这样的套接字的写操作将产生SIGPIPE信号。

  3. 使用非阻塞connect的套接字已建立连接，或者connect已经以失败告终。

  4. 其上有一个套接字错误待处理。对这样的套接字的写操作将不阻塞并返回-1（也就是返回一个错误），同时把errno设置成确切的错误条件。这些待处理的错误也可以通过指定SO_ERROR套接字选项调用getsockopt获取并清除。

-----

* #### TCP的数据编号与确认
  TCP将所要传送的整个报文(这可能包括许多个报文段)看成是一个个字节组成的数据流，并使每一个字节对应于一个序号。TCP的确认是对接收到的数据的最高序号(即收到的数据流中的最后一个序号)表示确认。但接收端返回的确认序号是已收到的数据的最高序号加1。也就是说，确认序号表示接收端期望下次收到的数据中的第一个数据字节的序号。

-----

* #### 在发送端，TCP是怎样决定发送个报文段的时机呢
  TCP有三种基本机制来控制报文段的发送。

    第一种机制是TCP维持一个变量，它等于最大报文段长度MSS，只要发送缓存从发送进程得到的数据达到MSS字节时，就组装成—个TCP报文段，然后发送出去。

    第二种机制是发送端的应用进程指明要求发送报文段，即TCP支持的推送(push)操作。

    第三种机制是发送端的一个计时器时间到了，这时就把当前已有的缓存数据装入报文段发送出去。

-----

* #### TCP流量控制：
  接受方告诉发送方自己的接受窗口大小，发送方调整自己的发送窗口大小。窗口以字节为单位。

    在TCP的实现中广泛使用Nagle算法：Nagle算法就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。若发送端应用进程将欲发送的数据逐个字节地达到发送端的TCP缓存，则发送端就将第一个字符(—个字符的长度是一个字节)发送出去，将后面到达的字符将都缓存起来。当接收端收到对第一个字符的确认后，再将缓存中的所有字符装成一个报文段发送出去，同时继续对随后到达的字符进行缓存。只有在收到对前一个报文段的确认时才继续发送下一个报文段。当字符到达较快而网络速率较慢时，用这样的方法可明显的减少所用的网络带宽，算法还规定，当到达的字符已达到窗口大小的一半或己达到报文段的最大长度时，就立即发送一个报文段。

-----

* #### Nagle算法的规则：
  - 如果包长度达到MSS，则允许发送；
  - 如果该包含有FIN，则允许发送；
  - 设置了TCP_NODELAY选项，则允许发送；
  - 未设置TCP_CORK选项时，若所有发出的小数据包（长度小于MSS）均被确认，则允许发送；
  - 上述条件都未满足，但发生了超时（一般为200ms），则立即发送。

-----

* #### 糊涂窗口综合症(silly window syndrome)
  有时也会使TCP的性能变坏。

    设想这种情况：接收端的缓存已满，而交互的应用进程一次只从缓存中读取一个字符(这样就在缓存产生1个字节的空位，然后向发送端发送确认，并将窗口设置为1个字节(但发送的数据报是40字节长)。接着，发送端又传来1个字符(但发来的IP数据报是41字节长。接收端发回确认，仍然将窗口设置为一个字节。这样进行下去，网络的效率将会很低。

    要解决这个问题，可让接收端等待一段时间，使得或者缓存已能有足够的空间容纳—个最长的报文段，或者缓存已有一半的中间处于空的状态。只要出现这两种情况之一，就发出确认报文，并向发送端通知当前的窗口大小。此外，发送端也不要发送太小的报文段，而是将数掘积累成足够大的报文段，或达到接收端缓存的空间的—半大小。

    上述两种方法（nagle和糊涂窗口）可配合使用。使得在发送端不发送很小的报文段的同时，接收端也不要在缓存刚刚有了一点小的空位置就急忙将一个很小的窗口大小通知给发送端。

-----

* #### 拥塞控制
  若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况叫做拥塞。所谓拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制是一个全局性过程，设计所有主机，所有的路由器。而流量控制是个端到端的问题。

    四种拥塞控制的算法：慢开始、拥塞避免、快重传、快恢复

    慢开始和拥塞避免（以下cwnd的大小单位都是报文段）

    发送方维持一个拥塞窗口cwnd, 发送方让发送窗口 等于 拥塞窗口和 接收方 接收窗口的最小值。

    发送方控制拥塞窗口的原则是：只要没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。

    慢开始 : 开始发送数据时，先探测一下，有小到大逐渐增大发送窗口。cwnd = 1, 然后每经过一个传输轮次就翻倍

    拥塞避免 : 让cwnd缓慢增大, 每经过一个传输轮次就+1

    慢开始门限ssthresh : 只要发送方判断网络出现拥塞（根据就是没有按时收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一般，然后把cwnd重新设定为1

    cwnd < ssthresh, 使用慢开始算法

    cwnd > ssthresh, 使用拥塞避免算法

    cwnd = ssthresh, 随意

    快重传和快恢复

    快重传 : 接收方及时发送确认, 而发送方只要一连收到三个重复确认, 马上重传而不等待重传计时器。（需要明确的是确认指的是确认收到的有序的最大分节序号）由于尽早重传未被确认的报文段，整的网络的吞吐量提高20%

    快恢复 : 当发送方一连收到三个重复确认时, ssthresh减半, cwnd设为ssthresh，然后执行拥塞避免算法。

-----

* #### 为什么要等待2MSL(Maximum Segment Lifetime)时间, 才从TIME_WAIT到CLOSED？
  这有两个理由：

  1. 保证A发送的最后一个ACK报文能够到达B。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN+ACK片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。如果Client不等待一段时间，则有可能会对Server发来的FIN+ACK报文回以RST导致Server无法进入CLOSED状态。
  2. 防止旧连接请求报文影响新的连接。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。Client在发送完ACK后，再经过2MSL，就可以使本连接持续时间内所产生的所有报文段从网络中消失。

  更加接地气的解释 :

  第一次挥手 : A告诉B, 我没数据发了, 准备关闭连接了, 你要发送数据吗第二次挥手 : B发送最后的数据第三次挥手 : B告诉A, 我也要关闭连接了第四次挥手 : A告诉B你可以关闭了, 我这边也关闭了

-----

* #### TCP定时器
  1. 重传计时器：

    为了控制丢失的报文段或丢弃的报文段，也就是对报文段确认的等待时间。当TCP发送报文段时，就创建这个特定报文段的重传计时器，可能发生两种情况：若在计时器超时之前收到对报文段的确认，则撤销计时器；若在收到对特定报文段的确认之前计时器超时，则重传该报文，并把计时器复位；
    重传时间=2RTT；

    RTT的值应该动态计算。常用的公式是：`RTT=previous RTTi + （1-i）*current RTT`。i的值通常取90%，即新的RTT是以前的RTT值的90%加上当前RTT值的10%.

    Karn算法：对重传报文，在计算新的RTT时，不考虑重传报文的RTT。因为无法推理出：发送端所收到的确认是对上一次报文段的确认还是对重传报文段的确认。干脆不计入。

  2. 坚持计时器：persistent timer

  专门为对付零窗口通知而设立的。

  当发送端收到零窗口的确认时，就启动坚持计时器，当坚持计时器截止期到时，发送端TCP就发送一个特殊的报文段，叫探测报文段，这个报文段只有一个字节的数据。探测报文段有序号，但序号永远不需要确认，甚至在计算对其他部分数据的确认时这个序号也被忽略。探测报文段提醒接收端TCP，确认已丢失，必须重传。
  坚持计时器的截止期设置为重传时间的值，但若没有收到从接收端来的响应，则发送另一个探测报文段，并将坚持计时器的值加倍和并复位，发送端继续发送探测报文段，将坚持计时器的值加倍和复位，知道这个值增大到阈值为止（通常为60秒）。之后，发送端每隔60s就发送一个报文段，直到窗口重新打开为止；

  3. 保活计时器：keeplive timer

  每当服务器收到客户的信息，就将keeplive timer复位，超时通常设置2小时，若服务器超过2小时还没有收到来自客户的信息，就发送探测报文段，若发送了10个探测报文段（没75秒发送一个）还没收到响应，则终止连接。

  4. 时间等待计时器：Time_Wait Timer

  在连接终止期使用，当TCP关闭连接时，并不认为这个连接就真正关闭了，在时间等待期间，连接还处于一种中间过度状态。这样就可以时重复的fin报文段在到达终点后被丢弃，这个计时器的值通常设置为一格报文段寿命期望值的两倍。

---

### HTTP

* #### HTTP和HTTPS的区别

  * HTTP 的URL 以http:// 开头，而HTTPS 的URL 以https:// 开头
  * HTTP 是不安全的，而 HTTPS 是安全的
  * HTTP 标准端口是80 ，而 HTTPS 的标准端口是443
  * 在OSI 网络模型中，HTTP工作于应用层，而HTTPS 的安全传输机制工作在传输层
  * HTTP 无法加密，而HTTPS 对传输的数据进行加密
  * HTTP无需证书，而HTTPS 需要CA机构wosign的颁发的SSL证书

---

* #### 什么是Http协议无状态协议?怎么解决Http协议无状态协议?

  - 无状态协议对于事务处理没有记忆能力，缺少状态意味着如果后续处理需要前面的信息。也就是说，当客户端一次HTTP请求完成以后，客户端再发送一次HTTP请求，HTTP并不知道当前客户端是一个”老用户“。
  - 可以使用Cookie来解决无状态的问题，Cookie就相当于一个通行证，第一次访问的时候给客户端发送一个Cookie，当客户端再次来的时候，拿着Cookie(通行证)，那么服务器就知道这个是”老用户“。

---

* #### URI和URL的区别

  **URI，是uniform resource identifier，统一资源标识符，用来唯一的标识一个资源。**

  - Web上可用的每种资源如HTML文档、图像、视频片段、程序等都是一个来URI来定位的
  - URI一般由三部组成：
  - ①访问资源的命名机制
  - ②存放资源的主机名
  - ③资源自身的名称，由路径表示，着重强调于资源。

  **URL是uniform resource locator，统一资源定位器，它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。**

  - URL是Internet上用来描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上，特别是著名的Mosaic。
  - 采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。URL一般由三部组成：
  - ①协议(或称为服务方式)
  - ②存有该资源的主机IP地址(有时也包括端口号)
  - ③主机资源的具体地址。如目录和文件名等

  **URN，uniform resource name，统一资源命名，是通过名字来标识资源，比如mailto:java-net@java.sun.com。**

  - URI是以一种抽象的，高层次概念定义统一资源标识，而URL和URN则是具体的资源标识的方式。URL和URN都是一种URI。笼统地说，每个 URL 都是 URI，但不一定每个 URI 都是 URL。这是因为 URI 还包括一个子类，即统一资源名称 (URN)，它命名资源但不指定如何定位资源。上面的 mailto、news 和 isbn URI 都是 URN 的示例。

  在Java的URI中，**一个URI实例可以代表绝对的，也可以是相对的，只要它符合URI的语法规则。而URL类则不仅符合语义，还包含了定位该资源的信息，因此它不能是相对的。**

  **在Java类库中，URI类不包含任何访问资源的方法，它唯一的作用就是解析。**

  **相反的是，URL类可以打开一个到达资源的流。**

---

* #### 常用的HTTP方法有哪些？

  - GET： 用于请求访问已经被URI（统一资源标识符）识别的资源，可以通过URL传参给服务器
  - POST：用于传输信息给服务器，主要功能与GET方法类似，但一般推荐使用POST方式。
  - PUT： 传输文件，报文主体中包含文件内容，保存到对应URI位置。
  - HEAD： 获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效。
  - DELETE：删除文件，与PUT方法相反，删除对应URI位置的文件。
  - OPTIONS：查询相应URI支持的HTTP方法。

---

* #### HTTP请求报文与响应报文格式

  * 请求报文包含四部分：

    - 请求行：包含请求方法、URI、HTTP版本信息

    - 请求首部字段

    - 请求内容实体

    - 空行

  * 响应报文包含四部分：

    - 状态行：包含HTTP版本、状态码、状态码的原因短语

    - 响应首部字段

    - 响应内容实体

    - 空行

  * 常见的首部：

    - **通用首部字段（请求报文与响应报文都会使用的首部字段）**
      - Date：创建报文时间
      - Connection：连接的管理
      - Cache-Control：缓存的控制
      - Transfer-Encoding：报文主体的传输编码方式
    - **请求首部字段（请求报文会使用的首部字段）**
      - Host：请求资源所在服务器
      - Accept：可处理的媒体类型
      - Accept-Charset：可接收的字符集
      - Accept-Encoding：可接受的内容编码
      - Accept-Language：可接受的自然语言
    - **响应首部字段（响应报文会使用的首部字段）**
      - Accept-Ranges：可接受的字节范围
      - Location：令客户端重新定向到的URI
      - Server：HTTP服务器的安装信息
    - **实体首部字段（请求报文与响应报文的的实体部分使用的首部字段）**
      - Allow：资源可支持的HTTP方法
      - Content-Type：实体主类的类型
      - Content-Encoding：实体主体适用的编码方式
      - Content-Language：实体主体的自然语言
      - Content-Length：实体主体的的字节数
      - Content-Range：实体主体的位置范围，一般用于发出部分请求时使用

---

* #### HTTPS工作原理

  - 首先HTTP请求服务端生成证书，客户端对证书的有效期、合法性、域名是否与请求的域名一致、证书的公钥（RSA加密）等进行校验；
  - 客户端如果校验通过后，就根据证书的公钥的有效， 生成随机数，随机数使用公钥进行加密（RSA加密）；
  - 消息体产生的后，对它的摘要进行MD5（或者SHA1）算法加密，此时就得到了RSA签名；
  - 发送给服务端，此时只有服务端（RSA私钥）能解密。
  - 解密得到的随机数，再用AES加密，作为密钥（此时的密钥只有客户端和服务端知道）。

---

* #### 一次完整的HTTP请求所经历的7个步骤

  HTTP通信机制是在一次完整的HTTP通信过程中，Web浏览器与Web服务器之间将完成下列7个步骤：

  * 建立TCP连接

    ​        在HTTP工作开始之前，Web浏览器首先要通过网络与Web服务器建立连接，该连接是通过TCP来完成的，该协议与IP协议共同构建 Internet，即著名的TCP/IP协议族，因此Internet又被称作是TCP/IP网络。**HTTP是比TCP更高层次的应用层协议，根据规则， 只有低层协议建立之后才能，才能进行更层协议的连接，因此，首先要建立TCP连接，一般TCP连接的端口号是80。**

  * Web浏览器向Web服务器发送请求行

    ​        一旦建立了TCP连接，**Web浏览器就会向Web服务器发送请求命令**。例如：GET /sample/hello.jsp HTTP/1.1。

  * Web浏览器发送请求头

    ​        浏览器发送其请求命令之后，还要以头信息的形式向Web服务器发送一些别的信息，**之后浏览器发送了一空白行来通知服务器**，它已经结束了该头信息的发送。

  * Web服务器应答

    ​     客户机向服务器发出请求后，服务器会客户机回送应答， **HTTP/1.1 200 OK ，应答的第一部分是协议的版本号和应答状态码。**

  * Web服务器发送应答头

    ​      正如客户端会随同请求发送关于自身的信息一样，服务器也会随同应答向用户发送关于它自己的数据及被请求的文档。

  * Web服务器向浏览器发送数据

    ​      Web服务器向浏览器发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，**它就以Content-Type应答头信息所描述的格式发送用户所请求的实际数据**。

  * Web服务器关闭TCP连接

    ​      一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码：

```
Connection:keep-alive
```

​		TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。

​		建立TCP连接->发送请求行->发送请求头->（到达服务器）发送状态行->发送响应头->发送响应数据->断TCP连接

---

* #### 常见的HTTP状态码

  * 200：请求被正常处理
  * 204：请求被受理但没有资源可以返回
  * 206：客户端只是请求资源的一部分，服务器只对请求的部分资源执行GET方法，相应报文中通过Content-Range指定范围的资源。
  * 301：永久性重定向
  * 302：临时重定向
  * 303：与302状态码有相似功能，只是它希望客户端在请求一个URI的时候，能通过GET方法重定向到另一个URI上
  * 304：发送附带条件的请求时，条件不满足时返回，与重定向无关
  * 307：临时重定向，与302类似，只是强制要求使用POST方法
  * 400：请求报文语法有误，服务器无法识别
  * 401：请求需要认证
  * 403：请求的对应资源禁止被访问
  * 404：服务器无法找到对应资源
  * 500：服务器内部错误
  * 503：服务器正忙

---

* #### HTTP 1.1版本新特性

  - **默认持久连接节省通信量**，只要客户端服务端任意一端没有明确提出断开TCP连接，就一直保持连接，可以发送多次HTTP请求

  - **管线化，客户端可以同时发出多个HTTP请求，而不用一个个等待响应**

  - **断点续传**

    实际上就是利用HTTP消息头使用分块传输编码，将实体主体分块传输。

---

* #### HTTP优化方案

  * TCP复用：TCP连接复用是将多个客户端的HTTP请求复用到一个服务器端TCP连接上，而HTTP复用则是一个客户端的多个HTTP请求通过一个TCP连接进行处理。前者是负载均衡设备的独特功能；而后者是HTTP 1.1协议所支持的新功能，目前被大多数浏览器所支持。
  * 内容缓存：将经常用到的内容进行缓存起来，那么客户端就可以直接在内存中获取相应的数据了。
  * 压缩：将文本数据进行压缩，减少带宽
  * SSL加速（SSL Acceleration）：使用SSL协议对HTTP协议进行加密，在通道内加密并加速
  * TCP缓冲：通过采用TCP缓冲技术，可以提高服务器端响应时间和处理效率，减少由于通信链路问题给服务器造成的连接负担。

---

### RPC

* #### 什么是 RPC ？

  - RPC (Remote Procedure Call)即**远程过程调用**，是分布式系统常见的一种通信方法。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。
  - 除 RPC 之外，常见的多系统数据交互方案还有分布式消息队列、HTTP 请求调用、数据库和分布式缓存等。
  - 其中 RPC 和 HTTP 调用是没有经过中间件的，它们是端到端系统的直接数据交互。

  **简单的说**

  - RPC就是从一台机器（客户端）上通过参数传递的方式调用另一台机器（服务器）上的一个函数或方法（可以统称为服务）并得到返回的结果。
  - RPC会隐藏底层的通讯细节（不需要直接处理Socket通讯或Http通讯）。
  - 客户端发起请求，服务器返回响应（类似于Http的工作方式）RPC在使用形式上像调用本地函数（或方法）一样去调用远程的函数（或方法）。

---

* #### 为什么我们要用RPC?

  RPC 的主要目标是让构建分布式应用更容易，在提供强大的远程调用能力时不损失本地调用的语义简洁性。为实现该目标，RPC 框架需提供一种透明调用机制让使用者不必显式的区分本地调用和远程调用。

---

* #### RPC需要解决的三个问题

  RPC要达到的目标：远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。

  - **Call ID映射**。我们怎么告诉远程机器我们要**调用哪个函数呢**？在本地调用中，函数体是直接通过函数指针来指定的，我们调用具体函数，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，是无法调用函数指针的，因为两个进程的地址空间是完全不一样。所以，在RPC中，**所有的函数都必须有自己的一个ID**。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 <--> Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。
  - **序列化和反序列化**。客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，**不能通过内存来传递参数**。甚至有时候客户端和服务端使用的都**不是同一种语言**（比如服务端用C++，客户端用Java或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。
  - **网络传输**。远程调用往往是基于网络的，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西。

---

* #### 实现高可用RPC框架需要考虑到的问题

  - 既然系统采用分布式架构，那一个服务势必会有多个实例，要解决**如何获取实例的问题**。所以需要一个服务注册中心，比如在Dubbo中，就可以使用Zookeeper作为注册中心，在调用时，从Zookeeper获取服务的实例列表，再从中选择一个进行调用；
  - 如何选择实例呢？就要考虑负载均衡，例如dubbo提供了4种负载均衡策略；
  - 如果每次都去注册中心查询列表，效率很低，那么就要加缓存；
  - 客户端总不能每次调用完都等着服务端返回数据，所以就要支持异步调用；
  - 服务端的接口修改了，老的接口还有人在用，这就需要版本控制；
  - 服务端总不能每次接到请求都马上启动一个线程去处理，于是就需要线程池；
  - 
---
* #### 理论结构模型

  ![img](https://img2018.cnblogs.com/blog/1202296/201902/1202296-20190226210658382-952573095.png)

  RPC 服务端通过RpcServer去导出（export）远程接口方法，而客户端通过RpcClient去导入（import）远程接口方法。客户端像调用本地方法一样去调用远程接口方法，**RPC 框架提供接口的代理实现**，实际的调用将委托给代理RpcProxy。代理封装调用信息并将调用转交给RpcInvoker去实际执行。在客户端的RpcInvoker通过连接器RpcConnector去维持与服务端的通道RpcChannel，并使用RpcProtocol执行协议编码（encode）并将编码后的请求消息通过通道发送给服务端。

  RPC 服务端接收器RpcAcceptor接收客户端的调用请求，同样使用RpcProtocol执行协议解码（decode）。

  解码后的调用信息传递给RpcProcessor去控制处理调用过程，最后再委托调用给RpcInvoker去实际执行并返回调用结果。


  ![img](https://img2018.cnblogs.com/blog/1202296/201902/1202296-20190226210746766-1118530948.png)

---

* #### 主流的RPC框架

  服务治理型

  - **dubbo**：是阿里巴巴公司开源的一个Java高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。dubbo 已经与12年年底停止维护升级。
  - **dubbox**：是当当团队基于dubbo升级的一个版本。是一个分布式的服务架构，可直接用于生产环境作为SOA服务框架。dubbox资源链接
  - **motan**：是新浪微博开源的一个Java框架。它诞生的比较晚，起于2013年，2016年5月开源。Motan 在微博平台中已经广泛应用，每天为数百个服务完成近千亿次的调用。motan资源链接

---

* #### RPC实现原理

  [see this](https://www.jianshu.com/p/78f72ccf0377)

---

* #### **为什么使用消息队列？（MQ）**

  - 异步处理 - 相比于传统的串行、并行方式，提高了系统吞吐量。
  - 应用解耦 - 系统间通过消息通信，不用关心其他系统的处理。
  - 流量削锋 - 可以通过消息队列长度控制请求量；可以缓解短时间内的高并发请求。
  - 日志处理 - 解决大量日志传输。
  - 消息通讯 - 消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。

  **怎么保证 MQ 的高可用？**

  1. 将所有 Broker 和待分配的 Partition 排序
  2. 将第 i 个 Partition 分配到第（i mod n）个 Broker 上
  3. 将第 i 个 Partition 的第 j 个 Replica 分配到第（(i + j) mode n）个 Broker 上

  ![img](https://pic2.zhimg.com/80/v2-565e449a11bf1cd7d0c47b554c9acef5_1440w.jpg)

  **消息的顺序问题**

  消息有序指的是可以按照消息的发送顺序来消费。

  假如生产者产生了 2 条消息：M1、M2，假定 M1 发送到 S1，M2 发送到 S2，如果要保证 M1 先于 M2 被消费，怎么做？

  ![img](https://pic1.zhimg.com/80/v2-2a4b849880d30fdc02888e09b53765f8_1440w.jpg)

  **解决方案：**

  （1）保证生产者 - MQServer - 消费者是一对一对一的关系

  ![img](https://pic4.zhimg.com/80/v2-9e495ce7da37c95a3f781be8c9f4d947_1440w.jpg)

  **缺陷：**

  - 并行度就会成为消息系统的瓶颈（吞吐量不够）
  - 更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我们不得不花费更多的精力来解决阻塞的问题。 （2）通过合理的设计或者将问题分解来规避。
  - 不关注乱序的应用实际大量存在
  - 队列无序并不意味着消息无序 所以从业务层面来保证消息的顺序而不仅仅是依赖于消息系统，是一种更合理的方式。

  **消息重复问题**

  造成消息重复的根本原因：网络不可达

  所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？

  消费端处理消息的业务逻辑保持幂等性。只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。利用一张日志表来记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。

---

* #### Dubbo 的实现过程？

  ![img](https://pic2.zhimg.com/80/v2-09365f2a65939d5922e4b729c57b44e9_1440w.jpg)
  
---

* #### 节点角色：

  ![img](https://pic1.zhimg.com/80/v2-3f5d95be6195b56149a5a86f02f0d5c4_1440w.jpg)

---

* #### 调用关系：

  1. 务容器负责启动，加载，运行服务提供者
  2. 服务提供者在启动时，向注册中心注册自己提供的服务。
  3. 服务消费者在启动时，向注册中心订阅自己所需的服务。
  4. 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
  5. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
  6. 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。

---

* #### Dubbo 负载均衡策略有哪些？

  Random

  - 随机，按权重设置随机概率。
  - 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。

  RoundRobin

  - 轮循，按公约后的权重设置轮循比率。
  - 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。

  LeastActive

  - 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。
  - 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。

  ConsistentHash

  * 一致性 Hash，相同参数的请求总是发到同一提供者。
  * 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。
  * 缺省只对第一个参数 Hash，如果要修改，请配置 <dubbo:parameter key="hash.arguments" value="0,1" />
  * 缺省用 160 份虚拟节点，如果要修改，请配置 <dubbo:parameter key="hash.nodes" value="320" />

---

* #### Dubbo 集群容错策略 ？

  ![img](https://pic1.zhimg.com/80/v2-9c1e59a30cdbcb05fa149746ba6adc5c_1440w.jpg)

  - **Failover** - 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数(不含第一次)。
  - **Failfast** - 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。
  - **Failsafe** - 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。
  - **Failback** - 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。
  - **Forking** - 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。
  - **Broadcast** - 播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。

---

* #### 动态代理策略？

  Dubbo 作为 RPC 框架，首先要完成的就是跨系统，跨网络的服务调用。消费方与提供方遵循统一的接口定义，消费方调用接口时，Dubbo 将其转换成统一格式的数据结构，通过网络传输，提供方根据规则找到接口实现，通过反射完成调用。也就是说，消费方获取的是对远程服务的一个代理(Proxy)，而提供方因为要支持不同的接口实现，需要一个包装层(Wrapper)。调用的过程大概是这样：

  ![img](https://pic4.zhimg.com/80/v2-fa41c736787d0a595395356aaf8479fb_1440w.jpg)

  消费方的 Proxy 和提供方的 Wrapper 得以让 Dubbo 构建出复杂、统一的体系。而这种动态代理与包装也是通过基于 SPI 的插件方式实现的，它的接口就是ProxyFactory。

```
  @SPI("javassist")
  public interface ProxyFactory {
   @Adaptive({Constants.PROXY_KEY})
   <T> T getProxy(Invoker<T> invoker) throws RpcException;
   @Adaptive({Constants.PROXY_KEY})
   <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) throws RpcException;
  }
```

  ProxyFactory 有两种实现方式，一种是基于 JDK 的代理实现，一种是基于 javassist 的实现。ProxyFactory 接口上定义了@SPI("javassist")，默认为 javassist 的实现。

---

* #### Dubbo 支持哪些序列化协议？Hessian？Hessian 的数据结构？

1. dubbo 序列化，阿里尚不成熟的 java 序列化实现。
2. hessian2 序列化：hessian 是一种跨语言的高效二进制的序列化方式，但这里实际不是原生的 hessian2 序列化，而是阿里修改过的 hessian lite，它是 dubbo RPC 默认启用的序列化方式。
3. json 序列化：目前有两种实现，一种是采用的阿里的 fastjson 库，另一种是采用 dubbo 中自已实现的简单 json 库，一般情况下，json 这种文本序列化性能不如二进制序列化。
4. java 序列化：主要是采用 JDK 自带的 java 序列化实现，性能很不理想。
5. Kryo 和 FST：Kryo 和 FST 的性能依然普遍优于 hessian 和 dubbo 序列化。

---

* #### Hessian 序列化与 Java 默认的序列化区别？

Hessian 是一个轻量级的 remoting on http 工具，采用的是 Binary RPC 协议，所以它很适合于发送二进制数据，同时又具有防火墙穿透能力。

1. Hessian 支持跨语言串行
2. 比 java 序列化具有更好的性能和易用性

---

* #### 支持的语言比较多 **Protoco Buffer 是什么？**

  Protocol Buffer 是 Google 出品的一种轻量 & 高效的结构化数据存储格式，性能比 Json、XML 真的强！太！多！

---

* #### Protocol Buffer 的序列化 & 反序列化简单 & 速度快的原因是：

1. 编码 / 解码 方式简单（只需要简单的数学运算 = 位移等等）
2. 采用 Protocol Buffer 自身的框架代码 和 编译器 共同完成

---

* #### Protocol Buffer 的数据压缩效果好（即序列化后的数据量体积小）的原因是：

1. 采用了独特的编码方式，如 Varint、Zigzag 编码方式等等
2. 采用 T - L - V 的数据存储方式：减少了分隔符的使用 & 数据存储得紧凑

---

* #### 注册中心挂了可以继续通信吗？

  可以。Dubbo 消费者在应用启动时会从注册中心拉取已注册的生产者的地址接口，并缓存在本地。每次调用时，按照本地存储的地址进行调用。

---

* #### ZooKeeper 原理是什么？ZooKeeper 有什么用？

  ZooKeeper 是一个分布式应用协调系统，已经用到了许多分布式项目中，用来完成统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等工作。

![img](https://pic1.zhimg.com/80/v2-08895fabd26fad7b4fc8631ef3d90aa8_1440w.jpg)

1. 每个 Server 在内存中存储了一份数据；
2. Zookeeper 启动时，将从实例中选举一个 leader（Paxos 协议）；
3. Leader 负责处理数据更新等操作（Zab 协议）；
4. 一个更新操作成功，当且仅当大多数 Server 在内存中成功修改数据。

---

* #### Netty 有什么用？NIO/BIO/AIO 有什么用？有什么区别？

  Netty 是一个“网络通讯框架”。

  Netty 进行事件处理的流程。Channel是连接的通道，是 ChannelEvent 的产生者，而ChannelPipeline可以理解为 ChannelHandler 的集合。

![img](https://pic2.zhimg.com/80/v2-2825d621ad83e2e62e04047f3334592d_1440w.jpg)

---

* #### IO 的方式通常分为几种：

  * ​	同步阻塞的 BIO
  * 同步非阻塞的 NIO
  * 异步非阻塞的 AIO 在使用同步 I/O 的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。

  NIO 基于 Reactor，当 socket 有流可读或可写入 socket 时，操作系统会相应的通知引用程序进行处理，应用再将流读取到缓冲区或写入操作系统。也就是说，这个时候，已经不是一个连接就要对应一个处理线程了，而是有效的请求，对应一个线程，当连接没有数据时，是没有工作线程来处理的。

  与 NIO 不同，当进行读写操作时，只须直接调用 API 的 read 或 write 方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入 read 方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将 write 方法传递的流写入完毕时，操作系统主动通知应用程序。即可以理解为，read/write 方法都是异步的，完成后会主动调用回调函数。

---

* #### 为什么要进行系统拆分？拆分不用 Dubbo 可以吗？

  系统拆分从资源角度分为：应用拆分和数据库拆分。

  从采用的先后顺序可分为：水平扩展、垂直拆分、业务拆分、水平拆分。

![img](https://pic4.zhimg.com/80/v2-fb6ada97023005b430f9421756b80617_1440w.jpg)

​	是否使用服务依据实际业务场景来决定。

​	当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。

​	当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。

---

* #### Dubbo 和 Thrift 有什么区别？

  * Thrift 是跨语言的 RPC 框架。
  * Dubbo 支持服务治理，而 Thrift 不支持